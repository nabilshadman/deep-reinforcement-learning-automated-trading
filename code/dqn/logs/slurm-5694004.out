Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
/work/mdisspt/mdisspt/n2134758/condaenvs/envs/env-pytorch-1.13.1-gpu/lib/python3.10/site-packages/torch/cuda/memory.py:395: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
  warnings.warn(
Using device: cuda

Tesla V100-SXM2-16GB
Memory Usage:
Allocated: 0.0 GB
Cached:    0.0 GB
MLP(
  (layers): Sequential(
    (0): Linear(in_features=7, out_features=32, bias=True)
    (1): ReLU()
    (2): Linear(in_features=32, out_features=27, bias=True)
  )
)
episode: 1/4, episode end value: 2599.31, duration: 0:00:02.667760
episode: 2/4, episode end value: 29767.52, duration: 0:00:00.687277
episode: 3/4, episode end value: 28109.30, duration: 0:00:00.708460
episode: 4/4, episode end value: 68648.86, duration: 0:00:00.712252

CPU Memory Usage: 330.01171875 MB
GPU Utilisation: 0 %
Total GPU Memory: 16384.0 MB
Used GPU Memory: 226.8125 MB
